{% extends 'base.html' %}
{% load static %}

{% block title %}Evaluation Results - {{ evaluation_run.name }}{% endblock %}

{% block extra_css %}
<style>
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 15px;
        box-shadow: 0 8px 25px rgba(0,0,0,0.1);
        transition: transform 0.3s ease;
    }
    
    .metric-card:hover {
        transform: translateY(-5px);
    }
    
    .metric-value {
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 0.5rem;
    }
    
    .metric-label {
        font-size: 0.9rem;
        opacity: 0.9;
    }
    
    .performance-table {
        background: white;
        border-radius: 10px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
    }
    
    .chart-container {
        background: white;
        border-radius: 10px;
        padding: 1.5rem;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        margin-bottom: 1.5rem;
        height: 400px;
        position: relative;
    }
    
    .species-performance {
        border-left: 4px solid #667eea;
        padding-left: 1rem;
        margin-bottom: 1rem;
    }
    
    .status-badge {
        font-size: 0.9rem;
        padding: 0.5rem 1rem;
    }
    
    .detail-row {
        background: #f8f9fa;
        border-radius: 8px;
        padding: 1rem;
        margin-bottom: 0.5rem;
    }
</style>
{% endblock %}

{% block content %}
<div class="container-fluid">
    <!-- Header -->
    <div class="d-flex justify-content-between align-items-center mb-4">
        <div>
            <h1 class="h2 mb-1">üìä Evaluation Results</h1>
            <p class="text-muted mb-0">{{ evaluation_run.name }}</p>
        </div>
        <div>
            <a href="{% url 'image_processing:evaluation_runs_list' %}" class="btn btn-outline-primary me-2">
                <i class="fas fa-arrow-left me-2"></i>Back to Runs
            </a>
            <a href="{% url 'image_processing:analytics_dashboard' %}" class="btn btn-outline-success">
                <i class="fas fa-chart-line me-2"></i>Analytics Dashboard
            </a>
        </div>
    </div>

    <!-- Run Information -->
    <div class="card mb-4">
        <div class="card-header bg-primary text-white">
            <h5 class="mb-0"><i class="fas fa-info-circle me-2"></i>Evaluation Run Details</h5>
        </div>
        <div class="card-body">
            <div class="row">
                <div class="col-md-6">
                    <div class="detail-row">
                        <strong>Description:</strong> {{ evaluation_run.description|default:"No description provided" }}
                    </div>
                    <div class="detail-row">
                        <strong>Status:</strong> 
                        {% if evaluation_run.status == 'PENDING' %}
                            <span class="badge bg-warning status-badge">‚è≥ Pending</span>
                        {% elif evaluation_run.status == 'COMPLETED' %}
                            <span class="badge bg-success status-badge">‚úÖ Completed</span>
                        {% elif evaluation_run.status == 'FAILED' %}
                            <span class="badge bg-danger status-badge">‚ùå Failed</span>
                        {% else %}
                            <span class="badge bg-secondary status-badge">{{ evaluation_run.get_status_display }}</span>
                        {% endif %}
                    </div>

                    <!-- Progress Information (updated by JavaScript) -->
                    <div class="progress-info" style="display: {% if evaluation_run.status == 'PENDING' or evaluation_run.status == 'PROCESSING' %}block{% else %}none{% endif %}">
                        {% if evaluation_run.status == 'PENDING' %}
                            <div class="alert alert-warning">
                                <i class="fas fa-clock me-2"></i>
                                <strong>Evaluation is queued.</strong> It will start processing shortly.
                            </div>
                        {% elif evaluation_run.status == 'PROCESSING' %}
                            <div class="mb-2">
                                <strong>Progress:</strong> Initializing...
                            </div>
                            <div class="progress">
                                <div class="progress-bar bg-info" role="progressbar" style="width: 0%"></div>
                            </div>
                        {% endif %}
                    </div>

                    <div class="detail-row">
                        <strong>Created:</strong> {{ evaluation_run.created_at|date:"F d, Y H:i" }}
                    </div>
                    {% if evaluation_run.completed_at %}
                    <div class="detail-row">
                        <strong>Completed:</strong> {{ evaluation_run.completed_at|date:"F d, Y H:i" }}
                    </div>
                    {% endif %}
                    {% if evaluation_run.processing_duration %}
                    <div class="detail-row">
                        <strong>Processing Time:</strong> {{ evaluation_run.processing_duration|floatformat:1 }} seconds
                    </div>
                    {% endif %}
                    {% if evaluation_run.total_images_evaluated and evaluation_run.processing_duration %}
                    <div class="detail-row">
                        <strong>Processing Speed:</strong> 
                        {% widthratio evaluation_run.total_images_evaluated evaluation_run.processing_duration.total_seconds 1 %} images/second
                    </div>
                    {% endif %}
                </div>
                <div class="col-md-6">
                    <div class="detail-row">
                        <strong>IoU Threshold:</strong> {{ evaluation_run.iou_threshold }}
                    </div>
                    <div class="detail-row">
                        <strong>Confidence Threshold:</strong> {{ evaluation_run.confidence_threshold }}
                    </div>
                    <div class="detail-row">
                        <strong>Models Evaluated:</strong>
                        <div class="mt-2">
                            {% for model in evaluation_run.models_evaluated %}
                            <span class="badge bg-primary me-1">{{ model }}</span>
                            {% empty %}
                            <span class="text-muted">No models specified</span>
                            {% endfor %}
                        </div>
                    </div>
                    <div class="detail-row">
                        <strong>Species Filter:</strong>
                        <div class="mt-2">
                            {% for species in evaluation_run.species_filter %}
                            <span class="badge bg-info me-1">{{ species }}</span>
                            {% empty %}
                            <span class="text-muted">All species included</span>
                            {% endfor %}
                        </div>
                    </div>
                    {% if evaluation_run.error_message %}
                    <div class="detail-row bg-danger text-white">
                        <strong>Error:</strong> {{ evaluation_run.error_message }}
                    </div>
                    {% endif %}
                    
                    <!-- Ground Truth Guidance Section -->
                    {% if evaluation_guidance %}
                    <div class="alert alert-info border border-info mt-3">
                        <div class="d-flex align-items-center mb-3">
                            <i class="fas fa-info-circle fa-2x text-info me-3"></i>
                            <div>
                                <h5 class="mb-1">{{ evaluation_guidance.issue }}</h5>
                                <p class="mb-0">{{ evaluation_guidance.explanation }}</p>
                            </div>
                        </div>
                        
                        <div class="row">
                            <div class="col-md-6">
                                <h6 class="text-primary">üìã Available Data:</h6>
                                <ul class="list-unstyled">
                                    {% for item in evaluation_guidance.available_data %}
                                    <li><i class="fas fa-check text-success me-2"></i>{{ item }}</li>
                                    {% endfor %}
                                </ul>
                            </div>
                            <div class="col-md-6">
                                <h6 class="text-primary">üí° Recommendations:</h6>
                                <ul class="list-unstyled">
                                    {% for suggestion in evaluation_guidance.suggestions %}
                                    <li><i class="fas fa-lightbulb text-warning me-2"></i>{{ suggestion }}</li>
                                    {% endfor %}
                                </ul>
                            </div>
                        </div>
                        
                        <div class="mt-3">
                            <small class="text-muted">
                                <strong>For thesis research:</strong> Consider using a properly annotated dataset or 
                                <a href="{% url 'image_processing:reviewed_analytics' %}" class="alert-link">review the processed results</a> 
                                for alternative analysis approaches.
                            </small>
                        </div>
                    </div>
                    {% endif %}
                </div>
            </div>
        </div>
    </div>

    <!-- Overall Performance Metrics -->
    <div class="row mb-4">
        <div class="col-md-3">
            <div class="card metric-card h-100 text-center p-3">
                <div class="metric-value" data-metric="map_50">{{ evaluation_run.overall_map_50|floatformat:3|default:"N/A" }}</div>
                <div class="metric-label">mAP@0.5</div>
            </div>
        </div>
        <div class="col-md-3">
            <div class="card metric-card h-100 text-center p-3">
                <div class="metric-value">{{ evaluation_run.overall_map_50_95|floatformat:3|default:"N/A" }}</div>
                <div class="metric-label">mAP@0.5:0.95</div>
            </div>
        </div>
        <div class="col-md-3">
            <div class="card metric-card h-100 text-center p-3">
                <div class="metric-value" data-metric="precision">{{ evaluation_run.overall_precision|floatformat:3|default:"N/A" }}</div>
                <div class="metric-label">Precision</div>
            </div>
        </div>
        <div class="col-md-3">
            <div class="card metric-card h-100 text-center p-3">
                <div class="metric-value" data-metric="recall">{{ evaluation_run.overall_recall|floatformat:3|default:"N/A" }}</div>
                <div class="metric-label">Recall</div>
            </div>
        </div>
        <div class="col-md-3">
            <div class="card metric-card h-100 text-center p-3">
                <div class="metric-value" data-metric="f1_score">{{ evaluation_run.overall_f1_score|floatformat:3|default:"N/A" }}</div>
                <div class="metric-label">F1-Score</div>
            </div>
        </div>
    </div>

    <!-- Model Performance Comparison -->
    <div class="row mb-4">
        <div class="col-12">
            <div class="performance-table">
                <div class="card-header bg-light">
                    <h5 class="mb-0"><i class="fas fa-robot me-2"></i>Model Performance Comparison</h5>
                </div>
                <div class="card-body">
                    <div class="table-responsive">
                        <table class="table table-hover">
                            <thead class="table-dark">
                                <tr>
                                    <th>Model</th>
                                    <th>mAP@0.5</th>
                                    <th>mAP@0.5:0.95</th>
                                    <th>Precision</th>
                                    <th>Recall</th>
                                    <th>F1-Score</th>
                                    <th>TP</th>
                                    <th>FP</th>
                                    <th>FN</th>
                                    <th>Avg Inference Time (ms)</th>
                                </tr>
                            </thead>
                            <tbody>
                                {% for model_metrics in model_metrics %}
                                <tr>
                                    <td><strong>{{ model_metrics.model_name }}</strong></td>
                                    <td>{{ model_metrics.map_50|floatformat:3|default:"0.000" }}</td>
                                    <td>{{ model_metrics.map_50_95|floatformat:3|default:"0.000" }}</td>
                                    <td>{{ model_metrics.precision|floatformat:3|default:"0.000" }}</td>
                                    <td>{{ model_metrics.recall|floatformat:3|default:"0.000" }}</td>
                                    <td>{{ model_metrics.f1_score|floatformat:3|default:"0.000" }}</td>
                                    <td>{{ model_metrics.true_positives|default:"0" }}</td>
                                    <td>{{ model_metrics.false_positives|default:"0" }}</td>
                                    <td>{{ model_metrics.false_negatives|default:"0" }}</td>
                                    <td>{{ model_metrics.avg_inference_time_ms|floatformat:1|default:"N/A" }}</td>
                                </tr>
                                {% empty %}
                                <tr>
                                    <td colspan="9" class="text-center text-muted">
                                        {% if evaluation_run.status == 'PENDING' %}
                                            <i class="fas fa-spinner fa-spin me-2"></i>Evaluation in progress...
                                        {% else %}
                                            No model metrics available
                                        {% endif %}
                                    </td>
                                </tr>
                                {% endfor %}
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Species Performance Breakdown -->
    <div class="row mb-4">
        <div class="col-12">
            <div class="performance-table">
                <div class="card-header bg-light">
                    <h5 class="mb-0"><i class="fas fa-dove me-2"></i>Species Performance Breakdown</h5>
                </div>
                <div class="card-body">
                    {% for species_metrics in species_metrics %}
                    <div class="species-performance">
                        <h6 class="text-primary">{{ species_metrics.species_name }}</h6>
                        <div class="row g-3">
                            <div class="col-md-2">
                                <small class="text-muted">mAP@0.5</small><br>
                                <strong>{{ species_metrics.map_50|floatformat:3|default:"0.000" }}</strong>
                            </div>
                            <div class="col-md-2">
                                <small class="text-muted">Precision</small><br>
                                <strong>{{ species_metrics.precision|floatformat:3|default:"0.000" }}</strong>
                            </div>
                            <div class="col-md-2">
                                <small class="text-muted">Recall</small><br>
                                <strong>{{ species_metrics.recall|floatformat:3|default:"0.000" }}</strong>
                            </div>
                            <div class="col-md-2">
                                <small class="text-muted">F1-Score</small><br>
                                <strong>{{ species_metrics.f1_score|floatformat:3|default:"0.000" }}</strong>
                            </div>
                            <div class="col-md-2">
                                <small class="text-muted">TP/FP/FN</small><br>
                                <strong>{{ species_metrics.true_positives|default:"0" }}/{{ species_metrics.false_positives|default:"0" }}/{{ species_metrics.false_negatives|default:"0" }}</strong>
                            </div>
                            <div class="col-md-2">
                                <small class="text-muted">Total Ground Truth</small><br>
                                <strong>{{ species_metrics.total_ground_truth|default:"0" }}</strong>
                            </div>
                        </div>
                    </div>
                    {% empty %}
                    <div class="text-center text-muted">
                        {% if evaluation_run.status == 'PENDING' %}
                            <i class="fas fa-spinner fa-spin me-2"></i>Species metrics will appear when evaluation completes...
                        {% else %}
                            <p>No species metrics available</p>
                        {% endif %}
                    </div>
                    {% endfor %}
                </div>
            </div>
        </div>
    </div>

    <!-- Visualizations -->
    <div class="row">
        <!-- Precision-Recall Curve -->
        <div class="col-lg-6">
            <div class="chart-container">
                <h5 class="mb-3"><i class="fas fa-chart-line me-2"></i>Precision-Recall Curve</h5>
                <canvas id="prCurve" height="300"></canvas>
            </div>
        </div>
        
        <!-- Confusion Matrix -->
        <div class="col-lg-6">
            <div class="chart-container">
                <h5 class="mb-3"><i class="fas fa-th me-2"></i>Confusion Matrix</h5>
                <canvas id="confusionMatrix" height="300"></canvas>
            </div>
        </div>
    </div>

    <!-- Image-Level Results -->
    <div class="row mb-4">
        <div class="col-12">
            <div class="performance-table">
                <div class="card-header bg-light">
                    <h5 class="mb-0"><i class="fas fa-images me-2"></i>Image-Level Performance</h5>
                </div>
                <div class="card-body">
                    <div class="table-responsive">
                        <table class="table table-hover">
                            <thead class="table-dark">
                                <tr>
                                    <th>Image</th>
                                    <th>Model</th>
                                    <th>Ground Truth Objects</th>
                                    <th>Detections</th>
                                    <th>True Positives</th>
                                    <th>False Positives</th>
                                    <th>False Negatives</th>
                                    <th>Image Precision</th>
                                    <th>Image Recall</th>
                                    <th>Image F1-Score</th>
                                </tr>
                            </thead>
                            <tbody>
                                {% for image_result in image_results %}
                                <tr>
                                    <td>
                                        {% if image_result.image_file %}
                                        <img src="{{ image_result.image_file.url }}" alt="Image" style="width: 50px; height: 50px; object-fit: cover; border-radius: 5px;">
                                        {% else %}
                                        <div class="bg-light d-flex align-items-center justify-content-center" style="width: 50px; height: 50px; border-radius: 5px;">
                                            <i class="fas fa-image text-muted"></i>
                                        </div>
                                        {% endif %}
                                    </td>
                                    <td><strong>{{ image_result.model_name|default:"N/A" }}</strong></td>
                                    <td>{{ image_result.ground_truth_count|default:"0" }}</td>
                                    <td>{{ image_result.detection_count|default:"0" }}</td>
                                    <td>{{ image_result.true_positives|default:"0" }}</td>
                                    <td>{{ image_result.false_positives|default:"0" }}</td>
                                    <td>{{ image_result.false_negatives|default:"0" }}</td>
                                    <td>{{ image_result.image_precision|floatformat:3|default:"N/A" }}</td>
                                    <td>{{ image_result.image_recall|floatformat:3|default:"N/A" }}</td>
                                    <td>{{ image_result.image_f1_score|floatformat:3|default:"N/A" }}</td>
                                </tr>
                                {% empty %}
                                <tr>
                                    <td colspan="10" class="text-center text-muted">
                                        {% if evaluation_run.status == 'PENDING' %}
                                            <i class="fas fa-spinner fa-spin me-2"></i>Image results will appear when evaluation completes...
                                        {% else %}
                                            No image-level results available
                                        {% endif %}
                                    </td>
                                </tr>
                                {% endfor %}
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Evaluation Summary -->
    <div class="row mt-4">
        <div class="col-12">
            <div class="alert alert-info">
                <h5><i class="fas fa-info-circle me-2"></i>Evaluation Summary</h5>
                <div class="row">
                    <div class="col-md-6">
                        <p><strong>Total Images Processed:</strong> {{ evaluation_run.total_images_evaluated|default:"0" }}</p>
                        <p><strong>Total Detections:</strong> {{ evaluation_run.total_predicted_objects|default:"0" }}</p>
                        <p><strong>Total Ground Truth Objects:</strong> {{ evaluation_run.total_ground_truth_objects|default:"0" }}</p>
                    </div>
                    <div class="col-md-6">
                        <p><strong>Overall F1-Score:</strong> {{ evaluation_run.overall_f1_score|floatformat:3|default:"N/A" }}</p>
                        <p><strong>Overall Precision:</strong> {{ evaluation_run.overall_precision|floatformat:3|default:"N/A" }}</p>
                        <p><strong>Overall Recall:</strong> {{ evaluation_run.overall_recall|floatformat:3|default:"N/A" }}</p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    {% if use_reviewed_fallback and reviewed_summary %}
    <!-- Reviewed Results Fallback (no label-based ground truth found) -->
    <div class="row mt-3">
        <div class="col-12">
            <div class="card border-0 shadow-sm">
                <div class="card-header bg-warning">
                    <h5 class="mb-0"><i class="fas fa-user-check me-2"></i>Reviewed Results Summary (No GT labels found)</h5>
                </div>
                <div class="card-body">
                    <p class="text-muted mb-3">Showing aggregates from Approved/Overridden results. Use this for thesis reporting when YOLO label files are not available.</p>
                    <div class="row">
                        <div class="col-lg-6">
                            <h6 class="text-primary">By Model</h6>
                            <div class="table-responsive">
                                <table class="table table-sm">
                                    <thead><tr><th>Model</th><th>Images</th><th>Total Detections</th><th>Avg Conf</th></tr></thead>
                                    <tbody>
                                        {% for model, m in reviewed_summary.models.items %}
                                        <tr>
                                            <td><strong>{{ model }}</strong></td>
                                            <td>{{ m.images }}</td>
                                            <td>{{ m.detections }}</td>
                                            <td>{{ m.avg_conf|floatformat:2 }}</td>
                                        </tr>
                                        {% empty %}
                                        <tr><td colspan="4" class="text-muted">No reviewed data</td></tr>
                                        {% endfor %}
                                    </tbody>
                                </table>
                            </div>
                        </div>
                        <div class="col-lg-6">
                            <h6 class="text-success">By Species</h6>
                            <div class="table-responsive">
                                <table class="table table-sm">
                                    <thead><tr><th>Species</th><th>Images</th><th>Total Detections</th><th>Avg Conf</th></tr></thead>
                                    <tbody>
                                        {% for species, s in reviewed_summary.species.items %}
                                        <tr>
                                            <td><strong>{{ species }}</strong></td>
                                            <td>{{ s.images }}</td>
                                            <td>{{ s.detections }}</td>
                                            <td>{{ s.avg_conf|floatformat:2 }}</td>
                                        </tr>
                                        {% empty %}
                                        <tr><td colspan="4" class="text-muted">No reviewed data</td></tr>
                                        {% endfor %}
                                    </tbody>
                                </table>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    {% endif %}

    <!-- Alternative Analysis for Small Datasets -->
    {% if evaluation_run.total_images_evaluated|default:0 < 5 %}
    <div class="row mb-4">
        <div class="col-12">
            <div class="card border-0 shadow-sm">
                <div class="card-header bg-light">
                    <h5 class="mb-0">
                        <i class="fas fa-search me-2"></i>Detailed Analysis
                    </h5>
                </div>
                <div class="card-body">
                    <div class="alert alert-warning">
                        <h6><i class="fas fa-info-circle me-2"></i>Limited Dataset Notice</h6>
                        <p>With only {{ evaluation_run.total_images_evaluated|default:0 }} image(s), statistical analysis is limited.
                        Here's a detailed breakdown of what we found:</p>
                    </div>

                    <div class="row">
                        <div class="col-md-6">
                            <h6 class="text-primary">üìä Detection Statistics</h6>
                            <div class="table-responsive">
                                <table class="table table-sm">
                                    <tbody>
                                        <tr>
                                            <td><strong>Images Processed:</strong></td>
                                            <td>{{ evaluation_run.total_images_evaluated|default:0 }}</td>
                                        </tr>
                                        <tr>
                                            <td><strong>Total Detections:</strong></td>
                                            <td>{{ evaluation_run.total_predicted_objects|default:0 }}</td>
                                        </tr>
                                        <tr>
                                            <td><strong>Ground Truth Objects:</strong></td>
                                            <td>{{ evaluation_run.total_ground_truth_objects|default:0 }}</td>
                                        </tr>
                                        <tr>
                                            <td><strong>Average Confidence:</strong></td>
                                            <td>
                                                {% if model_metrics %}
                                                    {% for model_metric in model_metrics %}
                                                        {{ model_metric.model_name }}: {{ model_metric.avg_confidence_score|floatformat:1 }}%
                                                        {% if not forloop.last %}<br>{% endif %}
                                                    {% endfor %}
                                                {% else %}
                                                    N/A
                                                {% endif %}
                                            </td>
                                        </tr>
                                    </tbody>
                                </table>
                            </div>
                        </div>

                        <div class="col-md-6">
                            <h6 class="text-success">üéØ Performance Insights</h6>
                            <div class="mb-3">
                                {% if evaluation_run.overall_precision|default:0 > 0 %}
                                    <div class="alert alert-success">
                                        <strong>Precision:</strong> {{ evaluation_run.overall_precision|floatformat:1 }}% -
                                        The model correctly identified {{ evaluation_run.total_ground_truth_objects|default:0 }} out of {{ evaluation_run.total_predicted_objects|default:0 }} detections
                                    </div>
                                {% endif %}

                                {% if evaluation_run.overall_recall|default:0 > 0 %}
                                    <div class="alert alert-info">
                                        <strong>Recall:</strong> {{ evaluation_run.overall_recall|floatformat:1 }}% -
                                        The model found most of the birds present in your images
                                    </div>
                                {% endif %}

                                {% if evaluation_run.overall_f1_score|default:0 > 0 %}
                                    <div class="alert alert-primary">
                                        <strong>F1-Score:</strong> {{ evaluation_run.overall_f1_score|floatformat:1 }}% -
                                        Balanced measure of precision and recall
                                    </div>
                                {% endif %}
                            </div>
                        </div>
                    </div>

                    <div class="mt-4">
                        <h6 class="text-warning">üìà Recommendations for Better Analysis</h6>
                        <div class="row">
                            <div class="col-md-4">
                                <div class="card bg-light">
                                    <div class="card-body text-center">
                                        <i class="fas fa-images fa-2x text-primary mb-2"></i>
                                        <h6>More Images</h6>
                                        <p class="small">Process 10+ images for reliable statistics</p>
                                    </div>
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="card bg-light">
                                    <div class="card-body text-center">
                                        <i class="fas fa-sliders-h fa-2x text-success mb-2"></i>
                                        <h6>Different Thresholds</h6>
                                        <p class="small">Test various confidence levels</p>
                                    </div>
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="card bg-light">
                                    <div class="card-body text-center">
                                        <i class="fas fa-balance-scale fa-2x text-info mb-2"></i>
                                        <h6>Compare Models</h6>
                                        <p class="small">Evaluate multiple YOLO versions</p>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    {% endif %}

    <!-- Enhanced Thesis Analysis Section -->
    {% if thesis_report and has_meaningful_metrics %}
    <div class="row mt-4">
        <div class="col-12">
            <div class="card border-0 shadow-sm">
                <div class="card-header bg-primary text-white">
                    <h5 class="mb-0"><i class="fas fa-graduation-cap me-2"></i>Thesis Analysis & Insights</h5>
                </div>
                <div class="card-body">
                    
                    <!-- Statistical Significance Analysis -->
                    {% if statistical_analysis %}
                    <div class="row mb-4">
                        <div class="col-12">
                            <h6 class="text-primary border-bottom pb-2"><i class="fas fa-chart-bar me-2"></i>Statistical Significance Analysis</h6>
                            
                            {% if statistical_analysis.pairwise_comparisons %}
                            <div class="table-responsive">
                                <table class="table table-sm">
                                    <thead class="table-light">
                                        <tr>
                                            <th>Model Comparison</th>
                                            <th>T-Statistic</th>
                                            <th>P-Value</th>
                                            <th>Significant?</th>
                                            <th>Effect Size</th>
                                            <th>Interpretation</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        {% for comparison, stats in statistical_analysis.pairwise_comparisons.items %}
                                        <tr>
                                            <td><strong>{{ comparison }}</strong></td>
                                            <td>{{ stats.t_statistic|floatformat:3 }}</td>
                                            <td>{{ stats.p_value|floatformat:4 }}</td>
                                            <td>
                                                {% if stats.significant %}
                                                    <span class="badge bg-success">Yes (p < 0.05)</span>
                                                {% else %}
                                                    <span class="badge bg-secondary">No (p ‚â• 0.05)</span>
                                                {% endif %}
                                            </td>
                                            <td>{{ stats.effect_size|floatformat:3 }}</td>
                                            <td>
                                                {% if stats.significant %}
                                                    {% if stats.effect_size > 0.8 %}
                                                        <span class="text-success">Large effect</span>
                                                    {% elif stats.effect_size > 0.5 %}
                                                        <span class="text-warning">Medium effect</span>
                                                    {% else %}
                                                        <span class="text-info">Small effect</span>
                                                    {% endif %}
                                                {% else %}
                                                    <span class="text-muted">No significant difference</span>
                                                {% endif %}
                                            </td>
                                        </tr>
                                        {% endfor %}
                                    </tbody>
                                </table>
                            </div>
                            {% else %}
                            <div class="alert alert-info">
                                <i class="fas fa-info-circle me-2"></i>
                                Statistical comparison requires multiple evaluation runs or K-fold validation.
                            </div>
                            {% endif %}
                        </div>
                    </div>
                    {% endif %}
                    
                    <!-- Enhanced Model Performance Metrics -->
                    {% if thesis_report.model_performance %}
                    <div class="row mb-4">
                        <div class="col-12">
                            <h6 class="text-primary border-bottom pb-2"><i class="fas fa-robot me-2"></i>Advanced Model Performance Metrics</h6>
                            <div class="table-responsive">
                                <table class="table table-hover">
                                    <thead class="table-dark">
                                        <tr>
                                            <th>Model</th>
                                            <th>F1-Score</th>
                                            <th>Precision</th>
                                            <th>Recall</th>
                                            <th>mAP@0.5</th>
                                            <th>Accuracy</th>
                                            <th>Specificity</th>
                                            <th>MCC</th>
                                            <th>Efficiency Score</th>
                                            <th>Inference Time</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        {% for model in thesis_report.model_performance %}
                                        <tr>
                                            <td><strong>{{ model.model_name }}</strong></td>
                                            <td>
                                                <span class="badge bg-{% if model.f1_score > 0.8 %}success{% elif model.f1_score > 0.6 %}warning{% else %}danger{% endif %}">
                                                    {{ model.f1_score|floatformat:3 }}
                                                </span>
                                            </td>
                                            <td>{{ model.precision|floatformat:3 }}</td>
                                            <td>{{ model.recall|floatformat:3 }}</td>
                                            <td>{{ model.map_50|floatformat:3 }}</td>
                                            <td>{{ model.accuracy|floatformat:3 }}</td>
                                            <td>{{ model.specificity|floatformat:3 }}</td>
                                            <td>{{ model.matthews_correlation|floatformat:3 }}</td>
                                            <td>
                                                <div class="progress" style="height: 20px;">
                                                    <div class="progress-bar bg-{% if model.efficiency_score > 0.8 %}success{% elif model.efficiency_score > 0.6 %}warning{% else %}danger{% endif %}" 
                                                         style="width: {{ model.efficiency_score|floatformat:0 }}%">
                                                        {{ model.efficiency_score|floatformat:2 }}
                                                    </div>
                                                </div>
                                            </td>
                                            <td>{{ model.avg_inference_time_ms|floatformat:1 }}ms</td>
                                        </tr>
                                        {% endfor %}
                                    </tbody>
                                </table>
                            </div>
                        </div>
                    </div>
                    {% endif %}
                    
                    <!-- Research Recommendations -->
                    {% if recommendations %}
                    <div class="row mb-4">
                        <div class="col-12">
                            <h6 class="text-primary border-bottom pb-2"><i class="fas fa-lightbulb me-2"></i>Research Recommendations</h6>
                            <div class="row">
                                {% for rec in recommendations %}
                                <div class="col-md-6 mb-3">
                                    <div class="card h-100 border-{% if rec.priority == 'HIGH' %}danger{% elif rec.priority == 'MEDIUM' %}warning{% else %}info{% endif %}">
                                        <div class="card-header bg-{% if rec.priority == 'HIGH' %}danger{% elif rec.priority == 'MEDIUM' %}warning{% else %}info{% endif %} text-white">
                                            <div class="d-flex justify-content-between align-items-center">
                                                <strong>{{ rec.category }}</strong>
                                                <span class="badge bg-light text-dark">{{ rec.priority }}</span>
                                            </div>
                                        </div>
                                        <div class="card-body">
                                            <h6 class="card-title">{{ rec.issue }}</h6>
                                            <p class="card-text">{{ rec.recommendation }}</p>
                                            {% if rec.target_metric %}
                                            <div class="mt-2">
                                                <small class="text-muted">
                                                    <strong>{{ rec.target_metric }}:</strong> 
                                                    Current {{ rec.current_value|floatformat:3 }} ‚Üí Target {{ rec.target_value|floatformat:3 }}
                                                </small>
                                            </div>
                                            {% endif %}
                                            {% if rec.details %}
                                            <div class="mt-2">
                                                <small class="text-muted">{{ rec.details }}</small>
                                            </div>
                                            {% endif %}
                                        </div>
                                    </div>
                                </div>
                                {% endfor %}
                            </div>
                        </div>
                    </div>
                    {% endif %}
                    
                    <!-- Error Analysis for Research Discussion -->
                    {% if error_analysis %}
                    <div class="row mb-4">
                        <div class="col-12">
                            <h6 class="text-primary border-bottom pb-2"><i class="fas fa-exclamation-triangle me-2"></i>Error Pattern Analysis</h6>
                            <div class="row">
                                {% if error_analysis.common_false_positives %}
                                <div class="col-md-6">
                                    <div class="card">
                                        <div class="card-header bg-warning text-dark">
                                            <h6 class="mb-0">Common False Positives</h6>
                                        </div>
                                        <div class="card-body">
                                            {% for error_type, count in error_analysis.common_false_positives.items %}
                                            <div class="d-flex justify-content-between align-items-center mb-2">
                                                <span>{{ error_type }}</span>
                                                <span class="badge bg-warning">{{ count }}</span>
                                            </div>
                                            {% endfor %}
                                        </div>
                                    </div>
                                </div>
                                {% endif %}
                                
                                {% if error_analysis.common_false_negatives %}
                                <div class="col-md-6">
                                    <div class="card">
                                        <div class="card-header bg-danger text-white">
                                            <h6 class="mb-0">Common False Negatives</h6>
                                        </div>
                                        <div class="card-body">
                                            {% for error_type, count in error_analysis.common_false_negatives.items %}
                                            <div class="d-flex justify-content-between align-items-center mb-2">
                                                <span>{{ error_type }}</span>
                                                <span class="badge bg-danger">{{ count }}</span>
                                            </div>
                                            {% endfor %}
                                        </div>
                                    </div>
                                </div>
                                {% endif %}
                            </div>
                        </div>
                    </div>
                    {% endif %}
                    
                    <!-- Methodology Summary for Thesis -->
                    <div class="row">
                        <div class="col-12">
                            <h6 class="text-primary border-bottom pb-2"><i class="fas fa-flask me-2"></i>Methodology Summary</h6>
                            <div class="alert alert-light">
                                <div class="row">
                                    <div class="col-md-6">
                                        <h6>Evaluation Parameters</h6>
                                        <ul class="list-unstyled">
                                            <li><strong>IoU Threshold:</strong> {{ evaluation_run.iou_threshold }}</li>
                                            <li><strong>Confidence Threshold:</strong> {{ evaluation_run.confidence_threshold }}</li>
                                            <li><strong>Total Images:</strong> {{ evaluation_run.total_images_evaluated }}</li>
                                            <li><strong>Models Compared:</strong> {{ total_models_compared }}</li>
                                        </ul>
                                    </div>
                                    <div class="col-md-6">
                                        <h6>Dataset Characteristics</h6>
                                        <ul class="list-unstyled">
                                            <li><strong>Ground Truth Objects:</strong> {{ evaluation_run.total_ground_truth_objects|default:"N/A" }}</li>
                                            <li><strong>Total Predictions:</strong> {{ evaluation_run.total_predicted_objects|default:"N/A" }}</li>
                                            <li><strong>Species Evaluated:</strong> 
                                                {% if evaluation_run.species_filter %}
                                                    {{ evaluation_run.species_filter|join:", " }}
                                                {% else %}
                                                    All available species
                                                {% endif %}
                                            </li>
                                            <li><strong>Processing Duration:</strong> 
                                                {% if evaluation_run.processing_duration %}
                                                    {{ evaluation_run.processing_duration.total_seconds|floatformat:1 }}s
                                                {% else %}
                                                    N/A
                                                {% endif %}
                                            </li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Export Options for Thesis -->
                    <div class="row mt-3">
                        <div class="col-12 text-end">
                            <div class="btn-group">
                                <button class="btn btn-outline-primary" onclick="exportResultsAsJSON()">
                                    <i class="fas fa-download me-2"></i>Export JSON
                                </button>
                                <button class="btn btn-outline-success" onclick="exportResultsAsCSV()">
                                    <i class="fas fa-file-csv me-2"></i>Export CSV
                                </button>
                                <button class="btn btn-outline-info" onclick="generateCitation()">
                                    <i class="fas fa-quote-right me-2"></i>Generate Citation
                                </button>
                            </div>
                        </div>
                    </div>
                    
                </div>
            </div>
        </div>
    </div>
    {% endif %}
</div>

<!-- Citation Modal -->
<div class="modal fade" id="citationModal" tabindex="-1">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">Research Citation</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal"></button>
            </div>
            <div class="modal-body">
                <div class="mb-3">
                    <label class="form-label">APA Style Citation:</label>
                    <textarea class="form-control" id="apaCitation" rows="3" readonly></textarea>
                </div>
                <div class="mb-3">
                    <label class="form-label">BibTeX Entry:</label>
                    <textarea class="form-control" id="bibtexCitation" rows="6" readonly></textarea>
                </div>
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Close</button>
                <button type="button" class="btn btn-primary" onclick="copyCitation('apa')">Copy APA</button>
                <button type="button" class="btn btn-primary" onclick="copyCitation('bibtex')">Copy BibTeX</button>
            </div>
        </div>
    </div>
</div>
{% endblock %}

{% block extra_js %}
<script src="https://cdn.jsdelivr.net/npm/chart.js@3.9.1/dist/chart.min.js"></script>
<script>
let statusCheckInterval;
let isEvaluationComplete = false;

document.addEventListener('DOMContentLoaded', function() {
    // Start real-time progress monitoring
    startProgressMonitoring();
    console.log('Initializing enhanced charts...');
    
    setTimeout(function() {
        try {
            // Enhanced Precision-Recall Curve with better handling for small datasets
            const prCanvas = document.getElementById('prCurve');
            if (prCanvas) {
                const totalImages = {{ evaluation_run.total_images_evaluated|default:0 }};
                const totalDetections = {{ evaluation_run.total_predicted_objects|default:0 }};

                // Generate synthetic PR curve data for small datasets
                const prData = {
                    labels: [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
                    datasets: []
                };

                {% if model_metrics %}
                    {% for model_metric in model_metrics %}
                    // Create more meaningful PR curve data
                    const modelPrecision = {{ model_metric.precision|default:0 }};
                    const modelRecall = {{ model_metric.recall|default:0 }};
                    const modelName = '{{ model_metric.model_name }}';

                    // For small datasets, create a simplified curve
                    if (totalImages < 5) {
                        // Create a simple curve from 0 to the actual values
                        const curveData = [];
                        for (let i = 0; i <= 10; i++) {
                            const recall = i / 10;
                            // Simulate a curve that reaches the actual precision/recall
                            const precision = recall <= modelRecall ?
                                Math.max(0.1, modelPrecision * (1 - Math.pow(recall / modelRecall - 1, 2))) :
                                modelPrecision * Math.exp(-(recall - modelRecall) * 5);
                            curveData.push(Math.max(0, precision));
                        }

                        prData.datasets.push({
                            label: `${modelName} (Estimated)`,
                            data: curveData,
                            borderColor: ('{{ forloop.counter|default:1 }}' === '1') ? '#667eea' : '#764ba2',
                            backgroundColor: ('{{ forloop.counter|default:1 }}' === '1') ? 'rgba(102, 126, 234, 0.1)' : 'rgba(118, 75, 162, 0.1)',
                            fill: false,
                            tension: 0.4,
                            borderDash: [5, 5]  // Dashed line to indicate estimation
                        });
                    } else {
                        // For larger datasets, use actual curve if available
                        prData.datasets.push({
                            label: modelName,
                            data: [modelPrecision, modelRecall],  // Single point for now
                            borderColor: ('{{ forloop.counter|default:1 }}' === '1') ? '#667eea' : '#764ba2',
                            backgroundColor: ('{{ forloop.counter|default:1 }}' === '1') ? 'rgba(102, 126, 234, 0.1)' : 'rgba(118, 75, 162, 0.1)',
                            fill: false,
                            tension: 0.4,
                            pointRadius: 8,
                            pointHoverRadius: 12
                        });
                    }
                    {% endfor %}
                {% endif %}

                if (prData.datasets.length > 0) {
                    new Chart(prCanvas.getContext('2d'), {
                        type: 'line',
                        data: prData,
                        options: {
                            responsive: true,
                            maintainAspectRatio: false,
                            plugins: {
                                title: {
                                    display: true,
                                    text: totalImages < 5 ?
                                        'Estimated Precision-Recall Curves (Limited Data)' :
                                        'Precision-Recall Curves by Model'
                                },
                                legend: {
                                    position: 'bottom'
                                },
                                tooltip: {
                                    callbacks: {
                                        afterLabel: function(context) {
                                            if (totalImages < 5) {
                                                return 'Note: Curve estimated from limited data';
                                            }
                                            return '';
                                        }
                                    }
                                }
                            },
                            scales: {
                                x: {
                                    title: { display: true, text: 'Recall' },
                                    min: 0, max: 1
                                },
                                y: {
                                    title: { display: true, text: 'Precision' },
                                    min: 0, max: 1
                                }
                            }
                        }
                    });
                    console.log('Enhanced PR Chart created');
                } else {
                    // No data available
                    const container = prCanvas.parentElement;
                    container.innerHTML = `
                        <div class="text-center py-4">
                            <i class="fas fa-chart-line fa-3x text-muted mb-3"></i>
                            <h5 class="text-muted">Precision-Recall Analysis</h5>
                            <p class="text-muted">Not enough data for curve generation</p>
                            <div class="alert alert-info">
                                <strong>üí° Suggestions:</strong>
                                <ul class="text-start mt-2">
                                    <li>Process more images to generate meaningful curves</li>
                                    <li>Run evaluation with different confidence thresholds</li>
                                    <li>Include images with varied detection scenarios</li>
                                </ul>
                            </div>
                        </div>
                    `;
                }
            }
            
            // Enhanced Confusion Matrix with better handling for small datasets
            const confCanvas = document.getElementById('confusionMatrix');
            if (confCanvas) {
                const totalImages = {{ evaluation_run.total_images_evaluated|default:0 }};
                const tp = {{ evaluation_run.total_ground_truth_objects|default:0 }};
                const fp = {{ evaluation_run.total_false_positives|default:0 }};
                const fn = {{ evaluation_run.total_false_negatives|default:0 }};
                const totalDetections = {{ evaluation_run.total_predicted_objects|default:0 }};

                const totalData = tp + fp + fn;

                if (totalData > 0) {
                    // Create enhanced confusion matrix with more informative display
                    const confusionData = {
                        labels: ['Correct Detections', 'False Alarms', 'Missed Objects'],
                        datasets: [{
                            data: [tp, fp, fn],
                            backgroundColor: ['#28a745', '#ffc107', '#dc3545'],
                            borderWidth: 2,
                            borderColor: '#fff'
                        }]
                    };

                    new Chart(confCanvas.getContext('2d'), {
                        type: 'doughnut',
                        data: confusionData,
                        options: {
                            responsive: true,
                            maintainAspectRatio: false,
                            plugins: {
                                title: {
                                    display: true,
                                    text: totalImages < 5 ?
                                        'Detection Summary (Limited Data)' :
                                        'Confusion Matrix Summary'
                                },
                                legend: {
                                    position: 'bottom'
                                },
                                tooltip: {
                                    callbacks: {
                                        afterLabel: function(context) {
                                            const index = context.dataIndex;
                                            const value = context.parsed;
                                            let explanation = '';

                                            switch(index) {
                                                case 0:
                                                    explanation = 'Birds correctly identified';
                                                    break;
                                                case 1:
                                                    explanation = 'False detections (noise/background)';
                                                    break;
                                                case 2:
                                                    explanation = 'Birds missed by the model';
                                                    break;
                                            }

                                            if (totalImages < 5) {
                                                explanation += '\nNote: Limited data may not be representative';
                                            }

                                            return explanation;
                                        }
                                    }
                                }
                            }
                        }
                    });
                    console.log('Enhanced Confusion Matrix created');
                } else {
                    // No data or all zeros - show informative alternative
                    const container = confCanvas.parentElement;
                    container.innerHTML = `
                        <div class="text-center py-4">
                            <i class="fas fa-chart-pie fa-3x text-muted mb-3"></i>
                            <h5 class="text-muted">Detection Analysis</h5>
                            <p class="text-muted">Insufficient data for confusion matrix</p>
                            <div class="row text-center mt-3">
                                <div class="col-4">
                                    <div class="border rounded p-2">
                                        <h4 class="text-success mb-1">${totalDetections}</h4>
                                        <small class="text-muted">Total Detections</small>
                                    </div>
                                </div>
                                <div class="col-4">
                                    <div class="border rounded p-2">
                                        <h4 class="text-primary mb-1">${tp}</h4>
                                        <small class="text-muted">Ground Truth</small>
                                    </div>
                                </div>
                                <div class="col-4">
                                    <div class="border rounded p-2">
                                        <h4 class="text-info mb-1">${totalImages}</h4>
                                        <small class="text-muted">Images</small>
                                    </div>
                                </div>
                            </div>
                            <div class="alert alert-info mt-3">
                                <strong>üí° For Better Analysis:</strong>
                                <ul class="text-start mt-2">
                                    <li>Process more images (recommended: 10+)</li>
                                    <li>Include images with known ground truth</li>
                                    <li>Run evaluations with varied scenarios</li>
                                    <li>Compare multiple models for insights</li>
                                </ul>
                            </div>
                        </div>
                    `;
                }
            }
            
        } catch (error) {
            console.error('Enhanced chart error:', error);
        }
    }, 100);

// Real-time progress monitoring functions
function startProgressMonitoring() {
    const runId = '{{ evaluation_run.id }}';
    const statusUrl = `/image-processing/api/evaluation/status/${runId}/`;

    // Check status immediately
    checkEvaluationStatus();

    // Then check every 3 seconds if still processing
    statusCheckInterval = setInterval(checkEvaluationStatus, 3000);
}

function checkEvaluationStatus() {
    const runId = '{{ evaluation_run.id }}';
    const statusUrl = `/image-processing/api/evaluation/status/${runId}/`;

    // Get CSRF token safely
    const csrfToken = document.querySelector('[name=csrfmiddlewaretoken]');
    const csrfValue = csrfToken ? csrfToken.value : '';

    fetch(statusUrl, {
        method: 'GET',
        headers: {
            'X-CSRFToken': csrfValue,
            'Content-Type': 'application/json'
        }
    })
    .then(response => response.json())
    .then(data => {
        updateProgressDisplay(data);

        // Stop monitoring if evaluation is complete
        if (data.status === 'COMPLETED' || data.status === 'FAILED') {
            clearInterval(statusCheckInterval);
            isEvaluationComplete = true;
            handleEvaluationComplete(data);
        }
    })
    .catch(error => {
        console.error('Error checking evaluation status:', error);
        showErrorMessage('Failed to check evaluation status. Please refresh the page.');
    });
}

function updateProgressDisplay(data) {
    // Early return if no data
    if (!data) {
        console.warn('No data provided to updateProgressDisplay');
        return;
    }

    const statusBadge = document.querySelector('.status-badge');
    const progressContainer = document.querySelector('.progress-container');
    const progressBar = document.querySelector('.progress-bar');

    // Update status badge if it exists
    if (statusBadge) {
        let statusClass = 'bg-warning';
        let statusIcon = '‚è≥';
        let statusText = 'Pending';

        switch (data.status) {
            case 'COMPLETED':
                statusClass = 'bg-success';
                statusIcon = '‚úÖ';
                statusText = 'Completed';
                break;
            case 'FAILED':
                statusClass = 'bg-danger';
                statusIcon = '‚ùå';
                statusText = 'Failed';
                break;
            case 'PROCESSING':
                statusClass = 'bg-info';
                statusIcon = 'üîÑ';
                statusText = 'Processing';
                break;
        }

        statusBadge.className = `badge ${statusClass} status-badge`;
        statusBadge.innerHTML = `${statusIcon} ${statusText}`;
    }

    // Update progress information
    const progressInfo = document.querySelector('.progress-info');
    if (progressInfo) {
        if (data.status === 'PROCESSING') {
            const percentage = data.progress_percentage || 0;
            progressInfo.innerHTML = `
                <div class="mb-2">
                    <strong>Progress:</strong> ${percentage}%
                </div>
                <div class="progress mb-2">
                    <div class="progress-bar bg-info" role="progressbar"
                         style="width: ${percentage}%" aria-valuenow="${percentage}"
                         aria-valuemin="0" aria-valuemax="100">
                    </div>
                </div>
                <small class="text-muted">${data.current_step || 'Initializing...'}</small>
            `;
        } else if (data.status === 'PENDING') {
            const tips = data.helpful_tips || [];
            const tipsHtml = tips.length > 0 ? `<ul class="mb-0 mt-2">${tips.map(tip => `<li>${tip}</li>`).join('')}</ul>` : '';

            progressInfo.innerHTML = `
                <div class="alert alert-warning">
                    <i class="fas fa-clock me-2"></i>
                    <strong>Evaluation is queued.</strong> It will start processing shortly.
                    ${tipsHtml}
                </div>
            `;
        }
    }

    // Update metrics if available and valid
    if (data && typeof data.overall_precision === 'number' && !isNaN(data.overall_precision)) {
        updateMetricValue('precision', data.overall_precision);
    }
    if (data && typeof data.overall_recall === 'number' && !isNaN(data.overall_recall)) {
        updateMetricValue('recall', data.overall_recall);
    }
    if (data && typeof data.overall_f1_score === 'number' && !isNaN(data.overall_f1_score)) {
        updateMetricValue('f1_score', data.overall_f1_score);
    }
    if (data && typeof data.overall_map_50 === 'number' && !isNaN(data.overall_map_50)) {
        updateMetricValue('map_50', data.overall_map_50);
    }
}

function updateMetricValue(metricType, value) {
    const elements = document.querySelectorAll(`[data-metric="${metricType}"]`);
    elements.forEach(element => {
        if (element) {
            element.textContent = (value * 100).toFixed(1) + '%';
        }
    });
}

function handleEvaluationComplete(data) {
    // Show completion message
    if (data.status === 'COMPLETED') {
        showSuccessMessage('‚úÖ Evaluation completed successfully! All metrics are now available.');
    } else if (data.status === 'FAILED') {
        showErrorMessage(`‚ùå Evaluation failed: ${data.error_message || 'Unknown error occurred'}`);
    }

    // Show helpful tips if available
    if (data.helpful_tips && data.helpful_tips.length > 0) {
        const tipsHtml = data.helpful_tips.map(tip => `<li>${tip}</li>`).join('');
        showInfoMessage(`<strong>Status Update:</strong><ul>${tipsHtml}</ul>`);
    }

    // Refresh the page after a short delay to show final results
    setTimeout(() => {
        window.location.reload();
    }, 2000);
}

function showSuccessMessage(message) {
    showMessage(message, 'success');
}

function showErrorMessage(message) {
    showMessage(message, 'danger');
}

function showInfoMessage(message) {
    showMessage(message, 'info');
}

function showProgressError(message) {
    if (message && typeof message === 'string') {
        showMessage(message, 'danger');
    } else {
        console.error('Invalid error message provided to showProgressError');
    }
}

function showMessage(message, type = 'info') {
    // Safety checks
    if (!message || typeof message !== 'string') {
        console.warn('Invalid message provided to showMessage');
        return;
    }

    if (!document || !document.body) {
        console.warn('Document or document.body not available');
        return;
    }

    // Remove existing messages
    const existingAlerts = document.querySelectorAll('.alert-dismissible');
    existingAlerts.forEach(alert => alert && alert.remove());

    // Create new alert
    const alertDiv = document.createElement('div');
    alertDiv.className = `alert alert-${type} alert-dismissible fade show position-fixed`;
    alertDiv.style.cssText = 'top: 20px; right: 20px; z-index: 9999; min-width: 300px;';
    alertDiv.innerHTML = `
        ${message}
        <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
    `;

    document.body.appendChild(alertDiv);

    // Auto-dismiss after 5 seconds
    setTimeout(() => {
        if (alertDiv.parentNode) {
            alertDiv.remove();
        }
    }, 5000);
}

// Handle page visibility changes
document.addEventListener('visibilitychange', function() {
    if (document.hidden) {
        // Pause monitoring when page is not visible
        if (statusCheckInterval && !isEvaluationComplete) {
            clearInterval(statusCheckInterval);
            console.log('Paused progress monitoring (page hidden)');
        }
    } else {
        // Resume monitoring when page becomes visible again
        if (!isEvaluationComplete) {
            statusCheckInterval = setInterval(checkEvaluationStatus, 3000);
            console.log('Resumed progress monitoring (page visible)');
        }
    }
});

// Utility function for redirecting to results (when called from modal)
function redirectToResults() {
    // Since we're already on the results page, just refresh to show final data
    console.log('Evaluation completed, refreshing page to show final results...');
    window.location.reload();
}

// Export functions for thesis data
function exportResultsAsJSON() {
    const data = {
        evaluation_run: {
            name: '{{ evaluation_run.name|escapejs }}',
            created_at: '{{ evaluation_run.created_at|date:"c" }}',
            total_images: {{ evaluation_run.total_images_evaluated|default:0 }},
            models_evaluated: {{ evaluation_run.models_evaluated|safe }},
            species_filter: {{ evaluation_run.species_filter|safe }},
            iou_threshold: {{ evaluation_run.iou_threshold }},
            confidence_threshold: {{ evaluation_run.confidence_threshold }}
        },
        overall_metrics: {
            precision: {{ evaluation_run.overall_precision|default:0 }},
            recall: {{ evaluation_run.overall_recall|default:0 }},
            f1_score: {{ evaluation_run.overall_f1_score|default:0 }},
            map_50: {{ evaluation_run.overall_map_50|default:0 }},
            map_50_95: {{ evaluation_run.overall_map_50_95|default:0 }}
        },
        {% if thesis_report %}
        thesis_report: {{ thesis_report|safe }},
        statistical_analysis: {{ statistical_analysis|safe }},
        {% endif %}
        exported_at: new Date().toISOString()
    };
    
    const blob = new Blob([JSON.stringify(data, null, 2)], { type: 'application/json' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `evaluation_results_${data.evaluation_run.name.replace(/[^a-zA-Z0-9]/g, '_')}.json`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
}

function exportResultsAsCSV() {
    let csvContent = "Model,F1-Score,Precision,Recall,mAP@0.5,Accuracy,Specificity,MCC,Efficiency Score,Inference Time (ms)\n";
    
    {% if thesis_report.model_performance %}
    {% for model in thesis_report.model_performance %}
    csvContent += "{{ model.model_name|escapejs }},{{ model.f1_score }},{{ model.precision }},{{ model.recall }},{{ model.map_50 }},{{ model.accuracy }},{{ model.specificity }},{{ model.matthews_correlation }},{{ model.efficiency_score }},{{ model.avg_inference_time_ms }}\n";
    {% endfor %}
    {% endif %}
    
    const blob = new Blob([csvContent], { type: 'text/csv' });
    const url = URL.createObjectURL(blob);
    const a = document.createElement('a');
    a.href = url;
    a.download = `model_performance_{{ evaluation_run.name|slugify }}.csv`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);
    URL.revokeObjectURL(url);
}

function generateCitation() {
    const evaluationName = '{{ evaluation_run.name|escapejs }}';
    const currentDate = new Date().toLocaleDateString('en-US', { 
        year: 'numeric', 
        month: 'long', 
        day: 'numeric' 
    });
    const year = new Date().getFullYear();
    const username = '{{ request.user.get_full_name|default:request.user.username|escapejs }}';
    
    // APA Citation
    const apaCitation = `${username}. (${year}). ${evaluationName}: YOLO Model Performance Evaluation for Bird Species Detection. Generated using Platform-AviCast Analytics. Retrieved ${currentDate}.`;
    
    // BibTeX Citation
    const bibtexCitation = `@misc{avicast_eval_${year},
    author = {${username}},
    title = {${evaluationName}: YOLO Model Performance Evaluation for Bird Species Detection},
    year = {${year}},
    note = {Generated using Platform-AviCast Analytics},
    url = {${window.location.href}},
    accessed = {${currentDate}}
}`;
    
    document.getElementById('apaCitation').value = apaCitation;
    document.getElementById('bibtexCitation').value = bibtexCitation;
    
    const citationModal = new bootstrap.Modal(document.getElementById('citationModal'));
    citationModal.show();
}

function copyCitation(type) {
    const textArea = document.getElementById(type === 'apa' ? 'apaCitation' : 'bibtexCitation');
    textArea.select();
    textArea.setSelectionRange(0, 99999); // For mobile devices
    
    try {
        document.execCommand('copy');
        showMessage(`${type.toUpperCase()} citation copied to clipboard!`, 'success');
    } catch (err) {
        showMessage('Failed to copy citation. Please select and copy manually.', 'warning');
    }
}
</script>
{% endblock %}
